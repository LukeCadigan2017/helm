{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/crfm-helm2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "import process_gens\n",
    "import pandas as pd\n",
    "from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "from typing import Any, List\n",
    "import json\n",
    "from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "import PostMetric\n",
    "import pandas as pd\n",
    "\n",
    "from helm.benchmark.metrics.statistic import Stat\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from helm.benchmark.augmentations.perturbation_description import (\n",
    "    PerturbationDescription)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from process_gen_utils import *\n",
    "from process_gens import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "# from typing import Any, List\n",
    "# import json\n",
    "# from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "# import PostMetric\n",
    "# import pandas as pd\n",
    "\n",
    "# from helm.benchmark.metrics.statistic import Stat\n",
    "# from typing import Dict, Optional\n",
    "\n",
    "# from helm.benchmark.augmentations.perturbation_description import (\n",
    "#     PerturbationDescription)\n",
    "# from dataclasses import dataclass\n",
    "# import os\n",
    "\n",
    "# def assert_dir_exists(dir_name):\n",
    "#     dirs=dir_name.split(\"/\")\n",
    "#     for i in range(len(dirs)):\n",
    "#         prev_dir=\"/\".join(dirs[:i])\n",
    "#         cur_dir=\"/\".join(dirs[:i+1])\n",
    "#         if not os.path.isdir(cur_dir):\n",
    "#             error_str=\"\\n------------------------------------------\\n\"\n",
    "#             error_str+=\"Error:\\n\"\n",
    "#             error_str+=f\"dir_name does not exist: {dir_name}\\n\\n\"\n",
    "#             error_str+=f\"Directory exists: {prev_dir}\\n\\n\"\n",
    "#             error_str+=f\"Extension does not exist: {dir_name[len(prev_dir)+1:]}\\n\"\n",
    "#             error_str+=f\"\\n\\nTo check:\\n\"\n",
    "#             error_str+=f\"ls {prev_dir}\"\n",
    "#             raise Exception(error_str)\n",
    "        \n",
    "\n",
    "\n",
    "# def get_process_gen_params(test_name):\n",
    "\n",
    "#     def get_metrics(mode):\n",
    "#         if(mode==\"wmt\"):\n",
    "#             task_names=[\"wmt_14_language_pair_de_en_\"]\n",
    "#             custom_metrics=[ PostMetric.BLEU1_METRIC(),PostMetric.BLEU4_METRIC()]\n",
    "#             instance_metrics=[\"comet\"]\n",
    "#         if(mode==\"instruct\"):\n",
    "#             print(\"\\n\\n----------------\\n NOTE: ONLY PRINTING 4 tasks ----------------\\n\")\n",
    "#             # task_names=[\"open_assistant:language=en,num_respondents=1,\",\"self_instruct:num_respondents=1,\"]\n",
    "#             task_names=[\n",
    "#                         # \"anthropic_hh_rlhf_subset_hh_num_respondents_1_\",\n",
    "#                         #  \"koala_num_respondents_1_\", \n",
    "#                         \"anthropic_hh_rlhf_subset_red_team_num_respondents_1_\",\n",
    "#                         \"self_instruct_num_respondents_1_\",\n",
    "#                         \"grammar_path_src_helm_benchmark_scenarios_best_chatgpt_prompts.yaml_tags_num_respondents_1_\",\n",
    "#                         \"vicuna_num_respondents_1_\"]\n",
    "#             custom_metrics=[]\n",
    "#             instance_metrics=[]\n",
    "        \n",
    "#         assert isinstance(task_names[0],str)\n",
    "#         return task_names, custom_metrics, instance_metrics\n",
    "\n",
    "#     root_folder=f\"snellius_copies/helm_output\"\n",
    "#     if(test_name==\"full_sample\"):\n",
    "#         mode = \"wmt\"\n",
    "#         suite_name=\"sample_return_20_eval_500\"\n",
    "        \n",
    "#         num_beams_list=[1]\n",
    "#         models=[\"meta_llama_Llama_3.1_8B_Instruct\"]\n",
    "#         eval_instances=500\n",
    "\n",
    "#     elif (test_name==\"full_instruct\"):\n",
    "#         mode=\"instruct\"\n",
    "#         suite_name=\"full_instruct_1_samples_100_evals\"\n",
    "        \n",
    "#         num_beams_list=[2,4]\n",
    "#         models=[\"allenai_OLMo_2_1124_13B_Instruct\"]\n",
    "#         eval_instances=100\n",
    "#     else:\n",
    "#         raise Exception(\"task name not found\")\n",
    "    \n",
    "#     task_names, custom_metrics, instance_metrics= get_metrics(mode)\n",
    "#     return root_folder, num_beams_list, models, custom_metrics, task_names, suite_name, instance_metrics\n",
    "    \n",
    "\n",
    "# @dataclass(frozen=False)\n",
    "# class PerInstanceStats:\n",
    "#     \"\"\"\n",
    "#     Captures a unit of evaluation.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Uniquely identifies the input instance\n",
    "#     instance_id: str\n",
    "#     train_trial_index: int\n",
    "#     \"\"\"Which replication\"\"\"\n",
    "\n",
    "#     stats: List[Stat]\n",
    "#     \"\"\"Statistics computed from the predicted output\"\"\"\n",
    "#     perturbation: Optional[PerturbationDescription]=None\n",
    "\n",
    "\n",
    "# ############ UTILS ############\n",
    "\n",
    "# def clean_str_for_os(str_to_clean:str):\n",
    "#     str_to_clean=str_to_clean.strip()\n",
    "#     chars = [\"=\",\",\",\":\", \"__\", \"-\", \"/\"]\n",
    "#     for char in chars:\n",
    "#         str_to_clean=str_to_clean.replace(char,\"_\")\n",
    "#     return str_to_clean\n",
    "\n",
    "\n",
    "# def get_run_folder(root_folder:str, num_beams:int, model:str, task_name: str, suite_name:str):\n",
    "    \n",
    "#     num_beams=clean_str_for_os(str(num_beams))\n",
    "#     model=clean_str_for_os(model)\n",
    "#     task_name=clean_str_for_os(task_name)\n",
    "#     suite_name=clean_str_for_os(suite_name)\n",
    "\n",
    "#     run_folder= f\"{root_folder}/{suite_name}/{task_name}/{model}/{num_beams}_beams/runs/{suite_name}\"\n",
    "#     assert_dir_exists(run_folder)\n",
    "#     return run_folder\n",
    "\n",
    "\n",
    "\n",
    "# ############ Gen Summary stuff ############\n",
    "\n",
    "# def clean_generation_summary(generationSummary:GenerationSummary)->GenerationSummary:\n",
    "#     def clean_instance_generation(instanceGenerations:InstanceGenerations)->InstanceGenerations:\n",
    "#         def clean_generated_output(generatedOutput:GeneratedOutput)-> GeneratedOutput:\n",
    "#             generatedOutput.text=truncate_sequence(generatedOutput.text)\n",
    "#             return generatedOutput\n",
    "#         instanceGenerations.examples=[clean_generated_output(generatedOutput=example) for example in instanceGenerations.examples]\n",
    "#         instanceGenerations.examples.sort(key=lambda x:float(x.logprob),reverse=True)\n",
    "#         completion=instanceGenerations.examples[0]\n",
    "#         instanceGenerations.completion=completion.text\n",
    "#         instanceGenerations.completion_logprob=completion.logprob\n",
    "#         return instanceGenerations\n",
    "#     generationSummary.instance_generations=[clean_instance_generation(instanceGenerations=instance_generation) for instance_generation in generationSummary.instance_generations]\n",
    "#     # assert len(generationSummary.instance_generations)==eval_instances\n",
    "#     # print(f\"number of instances: {len(generationSummary.instance_generations)}\")\n",
    "#     return generationSummary\n",
    "\n",
    "\n",
    "\n",
    "# def get_gen_summary_from_path(path) -> GenerationSummary:\n",
    "#     def json_to_instance_generation(instance_dict:dict) -> InstanceGenerations:\n",
    "#         def json_to_generated_output(generated_output_dict):\n",
    "#             generated_output=GeneratedOutput(**generated_output_dict)\n",
    "#             tokens = [Token(**token) for token in generated_output.tokens]\n",
    "#             generated_output.tokens=tokens\n",
    "#             return generated_output\n",
    "#         instance_generation = InstanceGenerations(**instance_dict)\n",
    "#         examples = [ json_to_generated_output(generated_output_dict) for generated_output_dict in instance_generation.examples]\n",
    "#         instance_generation.examples=examples\n",
    "#         return instance_generation\n",
    "#     # print(f\"Getting gen summary from: {path}\")\n",
    "#     with open(path,'r') as json_file:\n",
    "#         generation_summary_dict=json.load(json_file)\n",
    "#     generation_summary=GenerationSummary(**generation_summary_dict)\n",
    "#     instance_generations = [json_to_instance_generation(instance_dict)  for instance_dict in generation_summary.instance_generations ]\n",
    "#     generation_summary.instance_generations=instance_generations\n",
    "\n",
    "#     generation_summary=clean_generation_summary(generation_summary)\n",
    "#     return generation_summary\n",
    "\n",
    "\n",
    "# def get_gen_summary_from_run_folder(run_folder: str):\n",
    "#     gen_sum_raw_path=f\"{run_folder}/generation_summary.json\"\n",
    "#     gen_sum_metric_path=f\"{run_folder}/generation_summary_metrics.json\"\n",
    "#     input_path = gen_sum_metric_path if os.path.isfile(gen_sum_metric_path) else gen_sum_raw_path\n",
    "#     generation_summary=get_gen_summary_from_path(input_path)\n",
    "#     return generation_summary\n",
    "\n",
    "\n",
    "# def truncate_sequence(text:str, all_stops=[\"<|end_of_text|>\"]) -> str:\n",
    "#     for stop in all_stops:\n",
    "#         try:\n",
    "#             text = text[: text.index(stop)]\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_dict(root_folder, num_beams_list:List[int], models:List[float], task_names:List[str], suite_name:str, dict_function)->Dict[int, GenerationSummary]:\n",
    "#     per_model={}\n",
    "#     for model_idx, model in enumerate(models):        \n",
    "#         per_task={}\n",
    "#         for task_idx, task_name in enumerate(task_names):\n",
    "#             per_beam={}\n",
    "#             for num_beams in num_beams_list:\n",
    "#                 run_folder=get_run_folder(root_folder=root_folder, num_beams=num_beams, model=model, task_name=task_name, suite_name=suite_name)\n",
    "#                 obj=dict_function(run_folder)\n",
    "#                 per_beam[num_beams]=obj\n",
    "#             per_task[task_idx]=per_beam\n",
    "#         per_model[model_idx] = per_task\n",
    "#     return per_model\n",
    "\n",
    "\n",
    "# def calculate_instance_stats_dict(root_folder, num_beams_list:List[int], models:List[float], task_names:List[str], suite_name:str, instance_metrics:List[str])->Dict[int, List[PerInstanceStats]]:\n",
    "#     def json_to_run_instance_stats(run_folder, instance_metrics) -> List[PerInstanceStats]:\n",
    "#         path=run_folder+\"/per_instance_stats.json\"\n",
    "#         # print(f\"Analyzing path: {path}\")\n",
    "#         if not os.path.isfile(path):\n",
    "#             return None\n",
    "#         with open(path,'r') as json_file:\n",
    "#             list_instance_stats_dicts=json.load(json_file)\n",
    "        \n",
    "#         instance_id_to_stats_dict={}\n",
    "#         for list_instance_stats_dict in list_instance_stats_dicts:\n",
    "#             per_instance_stats = PerInstanceStats(**list_instance_stats_dict)\n",
    "#             stats = [Stat(**stat_dict) for stat_dict in per_instance_stats.stats]\n",
    "#             per_instance_stats.stats=stats\n",
    "#             stats_dict={}\n",
    "#             for stat in per_instance_stats.stats:\n",
    "#                 name = stat.name\n",
    "#                 if name[\"name\"] in instance_metrics and name[\"split\"]==\"test\" and \"perturbation\" not in name.keys():\n",
    "#                     stats_dict[name[\"name\"]]= stat.mean\n",
    "#             instance_id_to_stats_dict[per_instance_stats.instance_id]=stats_dict\n",
    "#         return instance_id_to_stats_dict\n",
    "#     dict_function = lambda run_folder: json_to_run_instance_stats(run_folder=run_folder, instance_metrics=instance_metrics)\n",
    "#     return calculate_dict(root_folder, num_beams_list, models, task_names, suite_name, dict_function)\n",
    "\n",
    "# def calculate_instances_dict(root_folder, num_beams_list:List[int], models:List[float], task_names:List[str], suite_name:str):\n",
    "#     def get_instance_dict_from_run_folder(run_folder):\n",
    "#         gen_summary= get_gen_summary_from_run_folder(run_folder)\n",
    "#         instance_dict={}\n",
    "#         for instance_generation in gen_summary.instance_generations:\n",
    "#             instance_dict[instance_generation.instance_id] = instance_generation\n",
    "#         return instance_dict\n",
    "#     return calculate_dict(root_folder, num_beams_list, models, task_names, suite_name,get_instance_dict_from_run_folder )\n",
    "\n",
    "# def get_metrics_dict(instances_dict:Dict[int, GenerationSummary], custom_metrics:List[PostMetric.PostMetric], instance_stats_dict):\n",
    "#     base_metrics=[PostMetric.TextMetric,PostMetric.SentenceLenMetric(),PostMetric.OutputProbMetric(),\n",
    "#                    PostMetric.InstanceIdMetric(), PostMetric.IsCompletionMetric()]\n",
    "#     metrics=base_metrics+custom_metrics\n",
    "#     metrics_dicts=[]   \n",
    "\n",
    "#     for model in instances_dict.keys():        \n",
    "#         for task_name in instances_dict[model].keys():\n",
    "#             for beam_num in instances_dict[model][task_name].keys():\n",
    "\n",
    "#                 instance_stats_per_run = instance_stats_dict[model][task_name][beam_num]\n",
    "\n",
    "#                 for instance_id, instance_generation in instances_dict[model][task_name][beam_num].items():\n",
    "#                     for idx,generated_output in enumerate(instance_generation.examples):\n",
    "#                         pd_metrics_dict=generated_output.stats_dict if generated_output.stats_dict  is not None else {} \n",
    "                        \n",
    "#                         pd_metrics_dict[\"beam_num\"]=beam_num\n",
    "#                         pd_metrics_dict[\"task_name\"]=task_name\n",
    "#                         pd_metrics_dict[\"model\"]=model\n",
    "                        \n",
    "#                         #fill out the metrics dict\n",
    "#                         for metric in metrics:\n",
    "#                             pd_metrics_dict=PostMetric.calculate_post_metric(pd_metrics_dict,metric,instance_generation,generated_output)\n",
    "                        \n",
    "\n",
    "#                         if(idx==0):\n",
    "#                             pd_metrics_dict[\"isCompletion\"]=(idx==0)\n",
    "#                             if(instance_generation.instance_id in instance_stats_per_run.keys()):\n",
    "#                                 completion_metrics_dict = instance_stats_per_run[instance_generation.instance_id]\n",
    "#                                 for stat_name, value in completion_metrics_dict.items():\n",
    "#                                     pd_metrics_dict[stat_name]= value\n",
    "#                         metrics_dicts.append(pd_metrics_dict)\n",
    "#     return metrics_dicts\n",
    "\n",
    "# get_first = lambda x: next(iter(x.values()))\n",
    "# # @classmethod  \n",
    "# # def get_instance_info(self, root_folder, num_beams_list:List[int], models:List[str], task_name: str, suite_name:str)->Dict[int, GenerationSummary]:\n",
    "# #     num_beams=num_beams_list[0]\n",
    "# #     model=models[0]\n",
    "# #     instance_infos= {}\n",
    "# #     instance_metrics=[PostMetric.ReferenceMetric()]\n",
    "\n",
    "# #     generation_summary=get_gen_summary(root_folder=root_folder, num_beams=num_beams, model=model, task_name=task_name, suite_name=suite_name)\n",
    "# #     for instance_generation in generation_summary.instance_generations:\n",
    "# #         instance_id=instance_generation.instance_id\n",
    "# #         if instance_id not in instance_infos.keys():\n",
    "# #             instance_dict={}\n",
    "# #             for metric in instance_metrics:\n",
    "# #                 instance_dict=PostMetric.calculate_post_metric(metrics_dict=instance_dict,metric=metric,instance_generation=instance_generation,generated_output=None)\n",
    "# #             instance_infos[instance_id]=instance_dict\n",
    "# #     return instance_infos\n",
    "\n",
    "\n",
    "# # @classmethod  \n",
    "# # def get_metrics_df(self, root_folder):\n",
    "\n",
    "# #     try:\n",
    "# #         metrics_file=f\"{root_folder}/metrics_csv.txt\"\n",
    "# #         raw_metric_df = pd.read_csv(metrics_file, header=None)\n",
    "# #         raw_metric_df.columns=[ \"model\", \"task\", \"beam_num\", \"metric\", \"value\"]\n",
    "# #         raw_metric_df.drop([\"task\"],axis=1)\n",
    "# #         metric_df = raw_metric_df.pivot(\n",
    "# #             index=[\"model\", \"beam_num\"],\n",
    "# #             columns=\"metric\",\n",
    "# #             values=\"value\"\n",
    "# #         ).reset_index()\n",
    "# #         metric_df.sort_values(\"beam_num\")\n",
    "# #         self.metric_df=metric_df\n",
    "# #         return metric_df\n",
    "# #     except:\n",
    "# #         return None\n",
    "\n",
    "\n",
    "\n",
    "# class ProcessGens:\n",
    "#     root_folder:str\n",
    "#     task_and_beam_num_to_summary:Dict[int, GenerationSummary]\n",
    "#     metrics_dict:List[Dict[str,any]]\n",
    "\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def init(self,root_folder:str, num_beams_list:List[int], models:List[float], custom_metrics:List[PostMetric.PostMetric],task_names:List[str], instance_metrics:Dict[int, Dict[str, Dict[str, float]]]=None, suite_name:str=\"\"):\n",
    "        \n",
    "#         self.root_folder=root_folder\n",
    "\n",
    "#         # #this is the pre-computed metrics\n",
    "#         # print(\"get_metrics_df\")\n",
    "#         # self.metrics_df=self.get_metrics_df(root_folder)\n",
    "#         # print(\"get_instance_info\")\n",
    "\n",
    "#         # #this is th\n",
    "#         # instance_info=self.get_instance_info(root_folder=root_folder, num_beams_list=num_beams_list, models=models,task_name= task_name,suite_name=suite_name)\n",
    "#         # self.instance_info=instance_info\n",
    "\n",
    "#         #get the generation summary for each task beam\n",
    "#         print(\"calculate_gen_summary_dict\")\n",
    "#         self.instances_dict=calculate_instances_dict(root_folder=root_folder, num_beams_list=num_beams_list, models=models,task_names=task_names, suite_name=suite_name)\n",
    "        \n",
    "        \n",
    "#         #get the run instance stats for each task and beam\n",
    "#         self.instance_stats_dict=calculate_instance_stats_dict(root_folder=root_folder, num_beams_list=num_beams_list, models=models, task_names=task_names, suite_name=suite_name, instance_metrics=instance_metrics)\n",
    "        \n",
    "\n",
    "#         print(\"get_metrics_dict\")\n",
    "#         self.metrics_dicts=get_metrics_dict(instances_dict=self.instances_dict, custom_metrics=custom_metrics, instance_stats_dict=self.instance_stats_dict)\n",
    "\n",
    "\n",
    "#         self.first_run_instances=get_first(get_first(get_first(self.instances_dict)))\n",
    "#         self.ids= list(self.first_run_instances.keys())\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------\n",
      " NOTE: ONLY PRINTING 4 tasks ----------------\n",
      "\n",
      "calculate_gen_summary_dict\n",
      "get_metrics_dict\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "processGens=ProcessGens()\n",
    "processGens.init_with_mode(\"full_instruct\")\n",
    "process_gen_params=processGens.params_dict \n",
    "root_folder=process_gen_params[\"root_folder\"]\n",
    "num_beams_list=process_gen_params[\"num_beams_list\"]\n",
    "models=process_gen_params[\"models\"]\n",
    "custom_metrics=process_gen_params[\"custom_metrics\"]\n",
    "task_names=process_gen_params[\"task_names\"]\n",
    "suite_name=process_gen_params[\"suite_name\"]\n",
    "instance_metrics=process_gen_params[\"instance_metrics\"]\n",
    "\n",
    "#if test\n",
    "# print(\"calculate_gen_summary_dict\")\n",
    "# gen_summary_dict=calculate_gen_summary_dict(root_folder=root_folder, num_beams_list=num_beams_list, models=models,task_names=task_names, suite_name=suite_name)\n",
    "# print(\"calculate instance dict\")\n",
    "# instance_stats_dict=calculate_instance_stats_dict(root_folder=root_folder, num_beams_list=num_beams_list, models=models, task_names=task_names, suite_name=suite_name, instance_metrics=instance_metrics)\n",
    "# print(\"get_metrics_dict\")\n",
    "# metrics_dicts=get_metrics_dict(gen_summary_dict=gen_summary_dict, custom_metrics=custom_metrics, instance_stats_dict=instance_stats_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "id10944\n",
      "First prompt\n",
      "Top of the morning\n",
      "Top of the morning\n"
     ]
    }
   ],
   "source": [
    "firstkey=next(iter(processGens.instances_dict.keys()))\n",
    "print(firstkey)\n",
    "secondKey=next(iter(processGens.instances_dict[firstkey].keys()))\n",
    "print(secondKey)\n",
    "thirdKey=next(iter(processGens.instances_dict[firstkey][secondKey].keys()))\n",
    "print(thirdKey)\n",
    "fourthKey=next(iter(processGens.instances_dict[firstkey][secondKey][thirdKey].keys()))\n",
    "print(fourthKey)\n",
    "print(\"First prompt\")\n",
    "print(processGens.instances_dict[firstkey][secondKey][thirdKey][fourthKey].prompt)\n",
    "\n",
    "\n",
    "print(processGens.instances_dict[0][0][2][\"id10944\"].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['example_themis', 'beam_num', 'task_name', 'model', 'text',\n",
      "       'completion_length', 'output_logprob', 'instanceID', 'isCompletion'],\n",
      "      dtype='object')\n",
      "Num examples: 2280\n",
      "Num completions: 760\n",
      "Index(['example_themis', 'beam_num', 'task_name', 'model', 'text',\n",
      "       'completion_length', 'output_logprob', 'instanceID', 'isCompletion'],\n",
      "      dtype='object')\n",
      "Mean example_themis for 4:\t 1.4052631578947368\n",
      "Mean example_themis for 2:\t 1.1736842105263159\n",
      "Pivot head:\n",
      "\n",
      "\n",
      "beam_num instanceID  task_name  model  example_themis_2  example_themis_4\n",
      "0               id0          3      0               0.0               0.0\n",
      "Mean Change:-0.23157894736842105\n",
      "Median Change:0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def compare_beams_by_metric(analysis_df,compare_metric,compare_beams, compare_func= lambda a,b: b-a,plot_histogram=True):\n",
    "\n",
    "    for beam_num in compare_beams:\n",
    "        filtered_df=analysis_df.loc[analysis_df['beam_num']==beam_num]\n",
    "        print(f\"Mean {compare_metric} for {beam_num}:\\t {filtered_df[compare_metric].mean()}\")\n",
    "    \n",
    "    compare_cols=[f\"{compare_metric}_{beam_num}\" for beam_num in compare_beams]\n",
    "    dif_col=f'{compare_metric}_dif'\n",
    "    \n",
    "    \n",
    "    index_cols=['instanceID',  'task_name', 'model']\n",
    "    \n",
    "    result = analysis_df[analysis_df['beam_num'].isin(compare_beams)][ [\"beam_num\"]+index_cols+[compare_metric]]\n",
    "\n",
    "    pivoted = analysis_df.pivot_table(\n",
    "        index=index_cols,\n",
    "        columns='beam_num',\n",
    "        values=compare_metric,\n",
    "        # aggfunc='mean'  # or 'first' if there's only one value per group\n",
    "    ).reset_index()\n",
    "\n",
    "    pivoted = pivoted.rename(columns={\n",
    "        compare_beams[0]: compare_cols[0],\n",
    "        compare_beams[1]: compare_cols[1]\n",
    "    })\n",
    "\n",
    "    print(\"Pivot head:\\n\\n\")\n",
    "    print(pivoted.head(1))\n",
    "\n",
    "\n",
    "    pivoted[dif_col] = pivoted.apply(lambda row: compare_func(row[compare_cols[0]],row[compare_cols[1]]), axis=1)\n",
    "    print(f\"Mean Change:{pivoted[dif_col].mean()}\")\n",
    "    print(f\"Median Change:{pivoted[dif_col].median()}\")\n",
    "    if(plot_histogram):\n",
    "        pivoted.hist(column=dif_col,bins=40)\n",
    "\n",
    "examples_df, completions_df=get_dfs(processGens=processGens, num_beams_list=num_beams_list)\n",
    "last_beam=num_beams_list[-1]\n",
    "first_beam=num_beams_list[0]\n",
    "print(completions_df.columns)\n",
    "# compare_beams_by_metric(analysis_df=completions_df,compare_metric='output_logprob', compare_beams=[last_beam, first_beam])\n",
    "compare_beams_by_metric(analysis_df=completions_df,compare_metric='example_themis', compare_beams=[last_beam, first_beam])\n",
    "# plot_keys(\"completion_logprob\",\"BLEU\")\n",
    "\n",
    "# x=completions_df[(completions_df[\"task_name\"]==0) & (completions_df[\"model\"]==0) & (completions_df[\"beam_num\"]==last_beam) & (completions_df[\"instanceID\"]==\"id33626\")   ]\n",
    "# print(x)\n",
    "\n",
    "\n",
    "# beam_num=next(iter(processGens.beam_num_to_summary))\n",
    "# instance_generations_by_id=get_instance_generations_by_id()\n",
    "# get_beam_means()\n",
    "# get_beam_probs()\n",
    "# check_completion_logprob(beam_num)\n",
    "# check_sentence_logprob(beam_num)\n",
    "# see_overlap_per_instance_generation(num_beams_list[-1], num_instances=10)\n",
    "\n",
    "# if(processGens.metrics_df is not None):\n",
    "#     ax1 = processGens.metrics_df.plot.scatter(x='beam_num',y='comet',c='DarkBlue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iterate_through_instances(processGens, instance_func, n_instances=10):\n",
    "\n",
    "    instances_dict=processGens.instances_dict\n",
    "    instance_stats_dict=processGens.instance_stats_dict\n",
    "    return_list=[]\n",
    "    for model in instances_dict.keys():        \n",
    "        for task_name in instances_dict[model].keys():\n",
    "            for beam_num in instances_dict[model][task_name].keys():\n",
    "                for instance_id, instance_generation in instances_dict[model][task_name][beam_num].items():\n",
    "                    instance_stats = instance_stats_dict[model][task_name][beam_num]\n",
    "                    obj=instance_func(instance_generation=instance_generation, instance_stats=instance_stats, model=model, task_name=task_name, beam_num=beam_num)\n",
    "                    return_list.append(obj)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "# dictionary should be:\n",
    "# model\n",
    "#   task_name\n",
    "#       instance_id\n",
    "#           prompt\n",
    "#           reference\n",
    "#           dict: beam_num\n",
    "#               rating\n",
    "#               completion \n",
    "#               evaluation\n",
    "# \n",
    "\n",
    "@dataclass(frozen=False)\n",
    "class SimplifiedCompletion:\n",
    "    rating:str\n",
    "    completion:str\n",
    "    evaluation:str\n",
    "\n",
    "@dataclass(frozen=False)\n",
    "class BeamOutputsPerInstance:\n",
    "    instance_id:int\n",
    "    reference:str\n",
    "    prompt:str\n",
    "    simplifiedCompletions:Dict[str,SimplifiedCompletion]\n",
    "\n",
    "\n",
    "\n",
    "from helm.common.general import ensure_directory_exists, write, asdict_without_nones\n",
    "\n",
    "\n",
    "def analyze_completion_by_beam(processGens:ProcessGens, num_instances:int=20):\n",
    "    instances_dict=processGens.instances_dict\n",
    "    \n",
    "\n",
    "    # model, task, beam_num\n",
    "    indexed_by_model={}\n",
    "    counter=0\n",
    "    for model_num,model in enumerate(models):\n",
    "        indexed_by_task={}\n",
    "        for task_num, task_name in enumerate(task_names):\n",
    "            \n",
    "            task_ids = list(instances_dict[0][task_num][num_beams_list[0]].keys())\n",
    "            indexed_by_id={}\n",
    "            for id in task_ids:\n",
    "                simplifiedCompletions={}\n",
    "                instance_id=None\n",
    "                reference=None\n",
    "                prompt=None\n",
    "                for beam_num in num_beams_list:\n",
    "                    instance_generation=instances_dict[model_num][task_num][beam_num][id]\n",
    "                    if(counter<1):\n",
    "                        # print(instance_generation.stats_dict)\n",
    "                        counter+=1\n",
    "                    rating = instance_generation.stats_dict[\"example_themis\"] if instance_generation.stats_dict else -1\n",
    "                    simplifiedCompletion= SimplifiedCompletion(completion=instance_generation.completion, evaluation=instance_generation.evaluation, rating=rating)\n",
    "                    simplifiedCompletions[beam_num]=simplifiedCompletion\n",
    "                    instance_id=instance_generation.instance_id\n",
    "                    reference=instance_generation.reference\n",
    "                    prompt=instance_generation.prompt\n",
    "                beamOutputsPerInstance = BeamOutputsPerInstance(instance_id=instance_id, prompt=prompt, reference=reference, simplifiedCompletions=simplifiedCompletions)\n",
    "                beamOutputsPerInstanceDict= asdict_without_nones(beamOutputsPerInstance)\n",
    "                indexed_by_id[id]=beamOutputsPerInstanceDict\n",
    "            indexed_by_task[task_name]=indexed_by_id\n",
    "        indexed_by_model[model]=indexed_by_task\n",
    "    return indexed_by_model\n",
    "data=analyze_completion_by_beam(processGens=processGens, num_instances=1)\n",
    "\n",
    "# print(data[models[0]][task_names[0]][processGens.ids[0]].simplifiedCompletions[num_beams_list[0]].completion)\n",
    "# print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 645021 characters to a.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# y=json.dumps(data, indent=2)\n",
    "# write(\"a.txt\",y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crfm-helm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
