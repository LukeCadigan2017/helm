{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_gens\n",
    "import pandas as pd\n",
    "from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "from typing import Any, List\n",
    "import json\n",
    "from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "import PostMetric\n",
    "import pandas as pd\n",
    "\n",
    "from helm.benchmark.metrics.statistic import Stat\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from helm.benchmark.augmentations.perturbation_description import (\n",
    "    PerturbationDescription)\n",
    "from dataclasses import dataclass\n",
    "from process_gens import ProcessGens\n",
    "# from process_gen_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(mode):\n",
    "    if(mode==\"wmt\"):\n",
    "        task_name=\"wmt\"\n",
    "        custom_metrics=[ PostMetric.BLEU1_METRIC(),PostMetric.BLEU4_METRIC()]\n",
    "        instance_metrics=[\"comet\"]\n",
    "    if(mode==\"instruct\"):\n",
    "        task_names=[\"open_assistant:language=en,num_respondents=1, self_instruct:num_respondents=1,\"]\n",
    "        custom_metrics=[]\n",
    "        instance_metrics=[]\n",
    "    return task_names, custom_metrics, instance_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # copied snellius test\n",
    "# num_beams_list=[32, 64]\n",
    "# models=[\"meta_llama_Llama_3.1_8B_Instruct\"]\n",
    "# eval_instances=5\n",
    "# task_name=\"wmt_14_language_pair_de_en_\"\n",
    "# root_folder=f\"snellius_copies/wmt_test\"\n",
    "# instance_metrics=[\"comet\"]\n",
    "\n",
    "# #local test\n",
    "# num_beams_list=[15,20]\n",
    "# root_folder=\"helm_output\"\n",
    "# eval_instances=3\n",
    "# models=[\"distilbert_distilgpt2\"]\n",
    "\n",
    "# copied snellius run\n",
    "# num_beams_list=[2,4,8,16,32,64,128]\n",
    "# num_beams_list=[2,64]\n",
    "\n",
    "# models=[\"meta_llama_Llama_3.1_8B_Instruct\"]\n",
    "# eval_instances=1000\n",
    "# root_folder=f\"snellius_copies/full\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Analyzing path: snellius_copies/helm_output/instruct_2_evals/open_assistant_language_en_num_respondents_1_/allenai_OLMo_2_1124_13B_Instruct/1_beams/runs/instruct_2_evals/per_instance_stats.json\n",
      "Getting gen summary from: snellius_copies/helm_output/instruct_2_evals/open_assistant_language_en_num_respondents_1_/allenai_OLMo_2_1124_13B_Instruct/1_beams/runs/instruct_2_evals/generation_summary_metrics.json\n",
      "number of instances: 2\n",
      "get_metrics_df\n",
      "get_instance_info\n",
      "Getting gen summary from: snellius_copies/helm_output/instruct_2_evals/open_assistant_language_en_num_respondents_1_/allenai_OLMo_2_1124_13B_Instruct/1_beams/runs/instruct_2_evals/generation_summary_metrics.json\n",
      "Analyzing path: snellius_copies/helm_output/instruct_2_evals/open_assistant_language_en_num_respondents_1_/allenai_OLMo_2_1124_13B_Instruct/1_beams/runs/instruct_2_evals/per_instance_stats.json\n",
      "calculate_beam_num_to_summary\n",
      "Getting gen summary from: snellius_copies/helm_output/instruct_2_evals/open_assistant_language_en_num_respondents_1_/allenai_OLMo_2_1124_13B_Instruct/1_beams/runs/instruct_2_evals/generation_summary_metrics.json\n",
      "number of instances: 2\n",
      "get_metrics_dict\n"
     ]
    }
   ],
   "source": [
    "# #always true\n",
    "# root_folder=\"snellius_copies/helm_output\"\n",
    "\n",
    "# #suite stuff\n",
    "# mode=\"instruct\"\n",
    "# suite_name=\"instruct_2_evals\"\n",
    "# #specifics\n",
    "# num_beams_list=[1]\n",
    "# models=[\"allenai_OLMo_2_1124_13B_Instruct\"]\n",
    "# eval_instances=2\n",
    "\n",
    "\n",
    "\n",
    "####################### For test #######################\n",
    "#always true\n",
    "root_folder=\"helm_output\"\n",
    "\n",
    "#suite stuff\n",
    "mode=\"instruct\"\n",
    "suite_name=\"instruct_1_evals\"\n",
    "\n",
    "#specifics\n",
    "num_beams_list=[1]\n",
    "models=[\"allenai_OLMo_2_1124_13B_Instruct\"]\n",
    "eval_instances=2\n",
    "\n",
    "\n",
    "test_process_gens=ProcessGens()\n",
    "\n",
    "task_names, custom_metrics, instance_metrics= get_metrics(mode)\n",
    "test_process_gens.init(root_folder=root_folder,num_beams_list=num_beams_list,models=models,custom_metrics=custom_metrics,task_names=task_names, eval_instances=eval_instances, suite_name=suite_name,instance_metrics=instance_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "# beam_num_to_instance_stats=test_process_gens.calculate_beam_num_to_run_instance_stats(root_folder=root_folder, num_beams_list=num_beams_list, models=models, task_name=task_name, suite_name=suite_name, instance_metrics=instance_metrics)\n",
    "# beam_num_to_summary=test_process_gens.calculate_beam_num_to_summary(root_folder=root_folder, num_beams_list=num_beams_list, models=models,eval_instances=eval_instances,task_name=task_name, suite_name=suite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'completions_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m last_beam\u001b[38;5;241m=\u001b[39mnum_beams_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m first_beam\u001b[38;5;241m=\u001b[39mnum_beams_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m compare_beams_by_metric(analysis_df\u001b[38;5;241m=\u001b[39m\u001b[43mcompletions_df\u001b[49m,compare_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_logprob\u001b[39m\u001b[38;5;124m'\u001b[39m, compare_beams\u001b[38;5;241m=\u001b[39m[last_beam, first_beam])\n\u001b[1;32m     15\u001b[0m compare_beams_by_metric(analysis_df\u001b[38;5;241m=\u001b[39mcompletions_df,compare_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomet\u001b[39m\u001b[38;5;124m'\u001b[39m, compare_beams\u001b[38;5;241m=\u001b[39m[last_beam, first_beam])\n\u001b[1;32m     16\u001b[0m plot_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_logprob\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'completions_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# beam_num=next(iter(processGens.beam_num_to_summary))\n",
    "# instance_generations_by_id=get_instance_generations_by_id()\n",
    "# get_beam_means()\n",
    "# get_beam_probs()\n",
    "# check_completion_logprob(beam_num)\n",
    "# check_sentence_logprob(beam_num)\n",
    "# see_overlap_per_instance_generation(num_beams_list[-1], num_instances=10)\n",
    "\n",
    "# if(processGens.metrics_df is not None):\n",
    "#     ax1 = processGens.metrics_df.plot.scatter(x='beam_num',y='comet',c='DarkBlue')\n",
    "\n",
    "last_beam=num_beams_list[-1]\n",
    "first_beam=num_beams_list[0]\n",
    "compare_beams_by_metric(analysis_df=completions_df,compare_metric='output_logprob', compare_beams=[last_beam, first_beam])\n",
    "compare_beams_by_metric(analysis_df=completions_df,compare_metric='comet', compare_beams=[last_beam, first_beam])\n",
    "plot_keys(\"completion_logprob\",\"BLEU\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crfm-helm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
