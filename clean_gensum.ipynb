{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/crfm-helm2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "from typing import Any, List\n",
    "import json\n",
    "from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "import ProcessGenMetrics\n",
    "import pandas as pd\n",
    "\n",
    "from helm.benchmark.metrics.statistic import Stat\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from helm.benchmark.augmentations.perturbation_description import (\n",
    "    PerturbationDescription)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gen_summary(path) -> GenerationSummary:\n",
    "    def json_to_instance_generation(instance_dict:dict) -> InstanceGenerations:\n",
    "        def json_to_generated_output(generated_output_dict):\n",
    "            generated_output=GeneratedOutput(**generated_output_dict)\n",
    "            tokens = [Token(**token) for token in generated_output.tokens]\n",
    "            generated_output.tokens=tokens\n",
    "            return generated_output\n",
    "        instance_generation = InstanceGenerations(**instance_dict)\n",
    "        examples = [ json_to_generated_output(generated_output_dict) for generated_output_dict in instance_generation.examples]\n",
    "        instance_generation.examples=examples\n",
    "        return instance_generation\n",
    "    \n",
    "    print(\"about to load!\")\n",
    "    with open(path,'r') as json_file:\n",
    "        generation_summary_dict=json.load(json_file, strict=False)\n",
    "    print(\"finished loading!\")\n",
    "    generation_summary=GenerationSummary(**generation_summary_dict)\n",
    "    instance_generations = [json_to_instance_generation(instance_dict)  for instance_dict in generation_summary.instance_generations ]\n",
    "    generation_summary.instance_generations=instance_generations\n",
    "    return generation_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'A', 'A']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"A\"]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path is /Users/lukecadigan/thesis/helm/jsons/olmo_instruct.json\n",
      "about to load!\n",
      "finished loading!\n",
      "/Users/lukecadigan/thesis/helm/jsons/olmo_instruct_clean.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file_base=\"/Users/lukecadigan/thesis/helm/jsons/instruct_summary\"\n",
    "# file_base=\"/Users/lukecadigan/thesis/helm/jsons/128_wmt\"\n",
    "file_base=\"/Users/lukecadigan/thesis/helm/jsons/olmo_instruct\"\n",
    "\n",
    "path=file_base+\".json\"\n",
    "print(f\"path is {path}\")\n",
    "generation_summary=get_gen_summary(path)\n",
    "new_path=file_base+\"_clean.json\"\n",
    "\n",
    "\n",
    "def add_tab(my_str:str, num_tabs:int=1):\n",
    "    tab_char = \"\".join( [\"\\t\"]*num_tabs)\n",
    "    # print(f\"tab_char is -{tab_char}-\")\n",
    "    return tab_char+my_str.replace(\"\\n\",\"\\n\"+tab_char)\n",
    "\n",
    "open(new_path, 'w').close()\n",
    "\n",
    "\n",
    "with open(new_path, \"a\") as file:\n",
    "    file.write(\"<><><><><><><><><><><><><><><><><><><><><><> Full Prompt Example <><><><><><><><><><><><><><><><><><><><><><>\\n\")\n",
    "    file.write(f\"{generation_summary.instance_generations[0].full_prompt}\")\n",
    "    file.write(\"<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\\n\\n\\n\")\n",
    "    for instance_generation in generation_summary.instance_generations:\n",
    "        file.write(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "        file.write(f\"Prompt:\\n{add_tab(instance_generation.prompt)}\\n\")\n",
    "        file.write(f\"Ref:\\n{add_tab(instance_generation.reference)}\\n\")\n",
    "        file.write(\"Examples\\n\")\n",
    "        for idx, example in enumerate(instance_generation.examples):\n",
    "            example_str=f\"{idx}: {example.text}\"\n",
    "            file.write(f\"{add_tab(example_str,1)}\\n\")\n",
    "print(new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crfm-helm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
