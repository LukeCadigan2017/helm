#Ok, so: run all tasks. Then, see what happens  
export NUM_TRAIN_TRIALS=1
export DEFAULT_METRICS=""
export SNELLIUS_METRICS=example_themis

export TASK_NAMES=""
export TASK_NAMES="${TASK_NAMES} self_instruct:num_respondents=1,"
export TASK_NAMES="${TASK_NAMES} anthropic_hh_rlhf:subset=hh,num_respondents=1,"
export TASK_NAMES="${TASK_NAMES} vicuna:num_respondents=1,"
export TASK_NAMES="${TASK_NAMES} koala:num_respondents=1,"
export TASK_NAMES="${TASK_NAMES} anthropic_hh_rlhf:subset=red_team,num_respondents=1,"
export TASK_NAMES="${TASK_NAMES} grammar:path=src/helm/benchmark/scenarios/best_chatgpt_prompts.yaml,tags=,num_respondents=1,"



touch local.env
. local.env

echo SNELLIUS METRICS IS $SNELLIUS_METRICS

#references, 252 tasks
#export TASK_NAMES="self_instruct:num_respondents=1,"
#no references, 169352 tasks
#export TASK_NAMES="anthropic_hh_rlhf:subset=hh,num_respondents=1,"
#no reference, 80 tasks
#export TASK_NAMES="vicuna:num_respondents=1,"
#no reference, 180
#export TASK_NAMES="koala:num_respondents=1,"
#no reference, 38961
#export TASK_NAMES="anthropic_hh_rlhf:subset=red_team,num_respondents=1,"
#3 references, 3670
#export TASK_NAMES="open_assistant:language=en,num_respondents=1,"
#no reference, 320
#export TASK_NAMES="grammar:path=src/helm/benchmark/scenarios/best_chatgpt_prompts.yaml,tags=,num_respondents=1,"
#export DEFAULT_METRICS="Helpfulness Understandability Completeness Conciseness Harmlessness Keyword_Feedback"


