{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/crfm-helm2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "from typing import Any, List\n",
    "import json\n",
    "from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "import PostMetric\n",
    "import pandas as pd\n",
    "\n",
    "from helm.benchmark.metrics.statistic import Stat\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from helm.benchmark.augmentations.perturbation_description import (\n",
    "    PerturbationDescription)\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from helm.common.request import (GeneratedOutput, Token)\n",
    "\n",
    "from helm.benchmark.runner import InstanceGenerations,GenerationSummary\n",
    "from typing import List\n",
    "from process_gens import get_completion_from_examples\n",
    "@dataclass(frozen=False)\n",
    "class FairseqOutput:\n",
    "    sentence_id:int=None\n",
    "    prompt:str=None\n",
    "    reference:str=None\n",
    "    generated_output:GeneratedOutput=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed 0\n",
      "Processing seed 1\n",
      "Processing seed 2\n",
      "Processing seed 3\n",
      "Processing seed 4\n",
      "Processing seed 5\n",
      "Processing seed 6\n",
      "Processing seed 7\n",
      "Processing seed 8\n",
      "Processing seed 9\n",
      "Processing seed 10\n",
      "Processing seed 11\n",
      "Processing seed 12\n",
      "Processing seed 13\n",
      "Processing seed 14\n",
      "Processing seed 15\n",
      "Processing seed 16\n",
      "Processing seed 17\n",
      "Processing seed 18\n",
      "Processing seed 19\n",
      "Processing seed 20\n",
      "Processing seed 21\n",
      "Processing seed 22\n",
      "Processing seed 23\n",
      "Processing seed 24\n",
      "Processing seed 25\n",
      "Processing seed 26\n",
      "Processing seed 27\n",
      "Processing seed 28\n",
      "Processing seed 29\n",
      "Processing seed 30\n",
      "Processing seed 31\n",
      "Processing seed 32\n",
      "Processing seed 33\n",
      "Processing seed 34\n",
      "Processing seed 35\n",
      "Processing seed 36\n",
      "Processing seed 37\n",
      "Processing seed 38\n",
      "Processing seed 39\n",
      "Processing seed 40\n",
      "Processing seed 41\n",
      "Processing seed 42\n",
      "Processing seed 43\n",
      "Processing seed 44\n",
      "Processing seed 45\n",
      "Processing seed 46\n",
      "Processing seed 47\n",
      "Processing seed 48\n",
      "Processing seed 49\n",
      "Processing seed 50\n",
      "Processing seed 51\n",
      "Processing seed 52\n",
      "Processing seed 53\n",
      "Processing seed 54\n",
      "Processing seed 55\n",
      "Processing seed 56\n",
      "Processing seed 57\n",
      "Processing seed 58\n",
      "Processing seed 59\n",
      "Processing seed 60\n",
      "Processing seed 61\n",
      "Processing seed 62\n",
      "Processing seed 63\n",
      "Processing seed 64\n",
      "Processing seed 65\n",
      "Processing seed 66\n",
      "Processing seed 67\n",
      "Processing seed 68\n",
      "Processing seed 69\n",
      "Processing seed 70\n",
      "Processing seed 71\n",
      "Processing seed 72\n",
      "Processing seed 73\n",
      "Processing seed 74\n",
      "Processing seed 75\n",
      "Processing seed 76\n",
      "Processing seed 77\n",
      "Processing seed 78\n",
      "Processing seed 79\n",
      "Processing seed 80\n",
      "Processing seed 81\n",
      "Processing seed 82\n",
      "Processing seed 83\n",
      "Processing seed 84\n",
      "Processing seed 85\n",
      "Processing seed 86\n",
      "Processing seed 87\n",
      "Processing seed 88\n",
      "Processing seed 89\n",
      "Processing seed 90\n",
      "Processing seed 91\n",
      "Processing seed 92\n",
      "Processing seed 93\n",
      "Processing seed 94\n",
      "Processing seed 95\n",
      "Processing seed 96\n",
      "Processing seed 97\n",
      "Processing seed 98\n",
      "Processing seed 99\n",
      "Num instance generations is 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fairseq_output=f\"/Users/lukecadigan/thesis/fairseq/{activation}_generate_results.txt\"\n",
    "# fairseq_output=f\"/Users/lukecadigan/thesis/helm/{activation}_results_mini.txt\"\n",
    "# '/Users/lukecadigan/thesis/fairseq/{activation}_results/seed_0/generate-test.txt'\n",
    "# fairseq_output=\"/Users/lukecadigan/thesis/fairseq/results/iwslt/{activation}/\"\n",
    "\n",
    "def get_fairset_output_from_lines(lines) -> FairseqOutput:\n",
    "    fairseq_output= FairseqOutput()\n",
    "    for i in range(0,num_lines, step_size):\n",
    "        logprobs=None\n",
    "        words=None\n",
    "        sentence_prob=None\n",
    "        sentence_text=None\n",
    "        \n",
    "        for raw_line in lines:\n",
    "            line=raw_line.strip()\n",
    "            split_on_tab = line.split(\"\\t\")\n",
    "\n",
    "\n",
    "            \n",
    "            id=split_on_tab[0]\n",
    "            split_id=id.split(\"-\")\n",
    "            indicator=split_id[0]\n",
    "            sentence_id=split_id[1]        \n",
    "            content=split_on_tab[-1]\n",
    "            content_prob = split_on_tab[1]if len(split_on_tab)==3 else None\n",
    "\n",
    "            #sanity check\n",
    "            if indicator in ['H', 'D']:\n",
    "                assert len(split_on_tab)==3\n",
    "            else: \n",
    "                assert len(split_on_tab)==2\n",
    "            # if indicator not in results_dict[sentence_id]:\n",
    "            if indicator == \"S\":\n",
    "                fairseq_output.prompt=content\n",
    "                fairseq_output.sentence_id=sentence_id\n",
    "            elif indicator == \"T\":\n",
    "                fairseq_output.reference=content\n",
    "            elif indicator == \"H\":\n",
    "                words=content.split(\" \")+[\"<eos>\"]\n",
    "                sentence_prob=content_prob\n",
    "            elif indicator == \"D\":\n",
    "                sentence_text=content\n",
    "            elif indicator == \"P\":\n",
    "                logprobs=content.split(\" \")\n",
    "        tokens=[]    \n",
    "        for logprob, text in zip(logprobs, words):\n",
    "            tokens.append(Token(text=text,logprob=logprob))\n",
    "        fairseq_output.generated_output = GeneratedOutput(text=sentence_text, logprob=sentence_prob, tokens=tokens)\n",
    "    return fairseq_output\n",
    "\n",
    "\n",
    "def fairseq_outputs_to_instance_generations(fairseq_output_list: List[FairseqOutput]) -> InstanceGenerations:\n",
    "    assert len(fairseq_output_list)>0\n",
    "    first_fairseq_output= fairseq_output_list[0]\n",
    "\n",
    "    examples=[fairseq_output.generated_output for fairseq_output in fairseq_output_list]\n",
    "    examples, completion, completion_logprob=get_completion_from_examples(examples)\n",
    "    return InstanceGenerations(instance_id=first_fairseq_output.sentence_id, \n",
    "                        prompt=first_fairseq_output.prompt, \n",
    "                        reference=first_fairseq_output.reference, \n",
    "                        completion=completion,\n",
    "                        completion_logprob=completion_logprob,\n",
    "                        full_prompt=first_fairseq_output.prompt,\n",
    "                        examples=examples \n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "fairseq_output_by_id={}\n",
    "num_outputs=1000\n",
    "\n",
    "\n",
    "#ensure that there are 2 outputs\n",
    "#ensure that there ids are 1749 and 3668\n",
    "\n",
    "activation=\"softmax\"\n",
    "for seed in range(100):\n",
    "    print(f\"Processing seed {seed}\")\n",
    "    fairseq_file=f\"/Users/lukecadigan/thesis/fairseq/results/iwslt/{activation}/seed_{seed}/generate-test.txt\"\n",
    "    step_size=5\n",
    "\n",
    "    \n",
    "    with open(fairseq_file, 'r') as file:    \n",
    "        all_lines=file.readlines()\n",
    "        len_all_lines=len(all_lines)\n",
    "        num_lines=min(num_outputs*step_size, len_all_lines)\n",
    "        # num_lines=len_all_lines\n",
    "        for i in range(0, num_lines, step_size):\n",
    "            \n",
    "            lines=all_lines[i:i+step_size]\n",
    "            fairseq_output :FairseqOutput= get_fairset_output_from_lines(lines)\n",
    "\n",
    "            if fairseq_output.sentence_id not in fairseq_output_by_id:\n",
    "                fairseq_output_by_id[fairseq_output.sentence_id]=[]\n",
    "            fairseq_output_by_id[fairseq_output.sentence_id].append(fairseq_output)\n",
    "instance_generations = [fairseq_outputs_to_instance_generations(fairseq_outputs) for fairseq_outputs in fairseq_output_by_id.values()]\n",
    "\n",
    "print(f\"Num instance generations is {len(instance_generations)}\")\n",
    "generation_summary=GenerationSummary(task_name=\"fairseq_wmt\",instance_generations=instance_generations, adapter_spec=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 90529871 characters to snellius_copies/helm_output/fairseq/wmt_14_language_pair_de_en_/fairseq_softmax/1_beams/runs/fairseq/generation_summary.json\n"
     ]
    }
   ],
   "source": [
    "from helm.common.general import write, asdict_without_nones\n",
    "\n",
    "# activation=\"sparsemax\"\n",
    "output_file_name=f\"snellius_copies/helm_output/fairseq/wmt_14_language_pair_de_en_/fairseq_{activation}/1_beams/runs/fairseq/generation_summary.json\"\n",
    "\n",
    "\n",
    "write(\n",
    "    output_file_name,\n",
    "    json.dumps(asdict_without_nones(generation_summary),indent=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      \n",
      "LOCAL_FILE=snellius_copies/helm_output/fairseq/wmt_14_language_pair_de_en_/fairseq_softmax/1_beams/runs/fairseq/generation_summary.json\n",
      "REMOTE_DIR_EXT=helm/helm_output/fairseq/wmt_14_language_pair_de_en_/fairseq_softmax/1_beams/runs/fairseq\n",
      "echo scp $LOCAL_FILE lcadigan@snellius.surf.nl:~/$REMOTE_DIR_EXT\n",
      "scp $LOCAL_FILE lcadigan@snellius.surf.nl:~/$REMOTE_DIR_EXT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "      \n",
    "LOCAL_FILE={output_file_name}\n",
    "REMOTE_DIR_EXT=helm/helm_output/fairseq/wmt_14_language_pair_de_en_/fairseq_{activation}/1_beams/runs/fairseq\n",
    "echo scp $LOCAL_FILE lcadigan@snellius.surf.nl:~/$REMOTE_DIR_EXT\n",
    "scp $LOCAL_FILE lcadigan@snellius.surf.nl:~/$REMOTE_DIR_EXT\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crfm-helm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
